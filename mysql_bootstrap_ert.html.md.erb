---
title: Recovering From MySQL Cluster Downtime
owner: RelEng
---

<strong><%= modified_date %></strong>

This topic describes the procedure for recovering a terminated Pivotal Application Service (PAS) MySQL cluster using the bootstrapping process.

You can bootstrap your cluster by using one of two methods:

- Run the bootstrap errand. See [Run the Bootstrap Errand](#assisted-bootstrap) below.
- Bootstrap manually. See [Bootstrap Manually](#manual-bootstrap) below.

<p class="note"><strong>Note:</strong> The procedures below assume you are using BOSH CLI v2 or later. For more information about BOSH v2, see <a href="https://bosh.io/docs/cli-v2/">Commands</a> in the BOSH documentation.</p>


## <a id='when'></a> When to Bootstrap

You must bootstrap a cluster that loses quorum. A cluster loses quorum when less than half of the nodes can communicate with each other for longer than the configured grace period. If a cluster does not lose quorum, individual unhealthy nodes automatically rejoin the cluster after resolving the error, restarting the node, or restoring connectivity. 

You can detect lost quorum through the following symptoms:

* All nodes appear "Unhealthy" on the proxy dashboard, viewable at `proxy-BOSH-JOB-INDEX.p-mysql.YOUR-SYSTEM-DOMAIN`:
  ![quorum lost](mysql-quorum-lost.png)
* All responsive nodes report the value of `wsrep_cluster_status` as `non-Primary`:

    <pre class="terminal">
    mysql> SHOW STATUS LIKE 'wsrep_cluster_status';
    +----------------------+-------------+
    | Variable_name        | Value       |
    +----------------------+-------------+
    | wsrep_cluster_status | non-Primary |
    +----------------------+-------------+
    </pre>

* All responsive nodes respond with `ERROR 1047` when queried with most statement types:

    <pre class="terminal">
    mysql> select * from mysql.user;
    ERROR 1047 (08S01) at line 1: WSREP has not yet prepared node for application use
    </pre>

See the [Cluster Scaling, Node Failure, and Quorum](http://docs.pivotal.io/p-mysql/1-8/cluster-behavior.html) topic for more details about determining cluster state.


## <a id="assisted-bootstrap"></a> Run the Bootstrap Errand

The following sections describe what the bootstrap errand is and how to use it based on the type of cluster failure.

### <a id="about-errand"></a> About the Bootstrap Errand

The bootstrap errand automates the steps described in the [Manual Bootstrapping](#manual-bootstrap) section below. It finds the node with the highest transaction sequence number and asks it to start up by itself in bootstrap mode. Finally, it asks the remaining nodes to join the cluster.

In most cases, running the errand recovers your cluster. But certain scenarios require additional steps.

### <a id="determine-failure"></a> Determine Type of Cluster Failure

To determine which set of instructions to follow, do the following:

1. Run the following command.

    ```
    bosh -e YOUR-ENV -d YOUR-DEPLOYMENT instances
    ```
    
    Where:
    - `YOUR-ENV` is the environment where you deployed the cluster.
    - `YOUR-DEPLOYMENT` is the deployment cluster name.

    For example:
    <pre class="terminal">
    $ bosh -e prod -d mysql instances
    </pre>

1. Find and record the `Process State` for your MySQL instances.
    <a id="vms"></a>In the following example output, the MySQL instances are in the `failing` process state.
    <pre class="terminal">
    Instance                                                             Process State  AZ             IPs
    backup-restore/c635410e-917d-46aa-b054-86d222b6d1c0                  running        us-central1-b  10.0.4.47
    bootstrap/a31af4ff-e1df-4ff1-a781-abc3c6320ed4                       -              us-central1-b  -
    broker-registrar/1a93e53d-af7c-4308-85d4-3b2b80d504e4                -              us-central1-b  10.0.4.58
    cf-mysql-broker/137d52b8-a1b0-41f3-847f-c44f51f87728                 running        us-central1-c  10.0.4.57
    cf-mysql-broker/28b463b1-cc12-42bf-b34b-82ca7c417c41                 running        us-central1-b  10.0.4.56
    deregister-and-purge-instances/4cb93432-4d90-4f1d-8152-d0c238fa5aab  -              us-central1-b  -
    monitoring/f7117dcb-1c22-495e-a99e-cf2add90dea9                      running        us-central1-b  10.0.4.48
    mysql/220fe72a-9026-4e2e-9fe3-1f5c0b6bf09b                           failing        us-central1-b  10.0.4.44
    mysql/28a210ac-cb98-4ab4-9672-9f4c661c57b8                           failing        us-central1-f  10.0.4.46
    mysql/c1639373-26a2-44ce-85db-c9fe5a42964b                           failing        us-central1-c  10.0.4.45
    proxy/87c5683d-12f5-426c-b925-62521529f64a                           running        us-central1-b  10.0.4.60
    proxy/b0115ccd-7973-42d3-b6de-edb5ae53c63e                           running        us-central1-c  10.0.4.61
    rejoin-unsafe/8ce9370a-e86b-4638-bf76-e103f858413f                   -              us-central1-b  -
    smoke-tests/e026aaef-efd9-4644-8d14-0811cb1ba733                     -              us-central1-b  10.0.4.59
    </pre>

1. Choose your scenario:
    * If your MySQL instances are in the `failing` state, continue to [Scenario 1](#cluster-disrupted).
    * If your MySQL instances are in the ` - ` state, continue to [Scenario 2](#vms-terminated).

### <a id="cluster-disrupted"></a> Scenario 1: Virtual Machines Running, Cluster Disrupted

In this scenario, the VMs are running, but the jobs are failing.

To bootstrap in this scenario, do the following:

1. Run the bootstrap errand.

    ```
    bosh -e YOUR-ENV -d YOUR-DEPLOYMENT run-errand bootstrap
    ```
    <p class='note'><strong>Note:</strong> The errand runs for a long time, during which no output is returned.</p>
    The command returns many lines of output, eventually with the following successful output:
    <pre class="terminal">
    Bootstrap errand completed
    [stderr]
    echo 'Started bootstrap errand ...'
    JOB\_DIR=/var/vcap/jobs/bootstrap
    CONFIG\_PATH=/var/vcap/jobs/bootstrap/config/config.yml
    /var/vcap/packages/bootstrap/bin/cf-mysql-bootstrap -configPath=/var/vcap/jobs/bootstrap/config/config.yml
    echo 'Bootstrap errand completed'
    exit 0
    Errand `bootstrap' completed successfully (exit code 0)
    </pre>
    
1. If the errand fails, run the bootstrap errand command again after a few minutes. The bootstrap errand may not work immediately.

1. If the errand fails after several tries, bootstrap your cluster manually. See [Bootstrap Manually](#manual-bootstrap) below.

### <a id="vms-terminated"></a> Scenario 2: Virtual Machines Terminated or Lost

In severe circumstances, such as a power failure, it is possible to lose all your VMs. 
You must recreate them before you can begin recovering the cluster.

When MySQL instances are in the ` - ` state, the VMs are lost. The procedures in this scenario bring the instances from a ` - ` state to a `failing` state. Then you run the bootstrap errand similar to [Scenario 1](#cluster-disrupted) above and restore configuration.

To recover terminated or lost VMs, do the procedures in the sections below:

1. [Recreate the Missing VMs](#recreate): Bring MySQL instances from a ` - ` state to a `failing` state.

1. [Run the Bootstrap Errand](#run-the-errand): Since your instances are now in the `failing` state, you continue similarly to [Scenario 1](#cluster-disrupted) above.

1. [Restore the BOSH Configuration](#reset-deployment): Go back to unignoring all instances and redeploy. This is a critical and mandatory step. 

<p class="warning note"><strong>WARNING:</strong> If you do not set each of your ignored instances to <code>unignore</code>, 
your instances are not updated in future deploys. You must perform the procedure in the final section of <em>Scenario 2</em>, 
<a href="#reset-deployment">Restore the BOSH Configuration</a>.</p>

##### <a id="recreate"></a> Recreate the Missing VMs

The procedure in this section uses BOSH to recreate the VMs, install software on them, and try to start the jobs. 

The procedure below allows you to do the following:

-  Redeploy your cluster while expecting the jobs to fail.

- Instruct BOSH to ignore the state of each instance in your cluster. This allows BOSH to deploy the software to each instance even if the instance is failing.

To recreate your missing VMs, do the following:

1. If BOSH resurrection is enabled, disable it.
    
    ```
    bosh -e YOUR-ENV update-resurrection off
    ```

1. Download the current manifest.
    
    ```
    bosh -e YOUR-ENV -d YOUR-DEPLOYMENT manifest > /tmp/manifest.yml
    ```

1. Redeploy and expect one of the MySQL VMs to fail. Deploying causes BOSH to create new VMs and install the software. Forming a cluster is in a subsequent step. 
    
    ```
    bosh -e YOUR-ENV -d YOUR-DEPLOYMENT deploy /tmp/manifest.yml
    ``` 

1. Run the following command and record the instance GUID of the VM that attempted to start. Your instance GUID is the string after `mysql/` in your BOSH instances output.
    
    ```
    bosh -e YOUR-ENV -d YOUR-DEPLOYMENT instances
    ```

1. Tell BOSH to ignore your MySQL instance. Ignoring the state allows BOSH to deploy software to the failed instance.
    
    ```
    bosh -e YOUR-ENV -d YOUR-DEPLOYMENT ignore mysql/INSTANCE_GUID
    ```
    Where:
    - `YOUR-ENV` is the environment where you deployed the cluster.
    - `YOUR-DEPLOYMENT` is the deployment cluster name.
    - `INSTANCE-GUID` is the string after `mysql/` in your BOSH instances output.
    For example:
    <pre class="terminal">
    $ bosh -e prod -d mysql ignore mysql/220fe72a-9026-4e2e-9fe3-1f5c0b6bf09b
    </pre>

1. Repeat steps 3 through 5 until all MySQL instances have attempted to start.

1. Re-enable BOSH resurrection if you disabled it in the first step.

    ```
    bosh -e YOUR-ENV update-resurrection on
    ```

1. See that your MySQL instances have gone from the ` - ` state to the `failing` state.

    ```
    bosh -e YOUR-ENV -d YOUR-DEPLOYMENT instances
    ```

##### <a id="run-the-errand"></a> Run the Bootstrap Errand 

All MySQL instances have a `failing` process state, but they now have the MySQL code installed on them. In this section, the bootstrap process recovers the cluster.

To bootstrap, do the following:

1. Run the bootstrap errand.

    ```
    bosh -e YOUR-ENV -d YOUR-DEPLOYMENT run-errand bootstrap
    ```
    <p class='note'><strong>Note:</strong> The errand runs for a long time, during which no output is returned.</p>
    The command returns many lines of output, eventually with the following successful output:
    <pre class="terminal">
    Bootstrap errand completed
    [stderr]
    echo 'Started bootstrap errand ...'
    JOB\_DIR=/var/vcap/jobs/bootstrap
    CONFIG\_PATH=/var/vcap/jobs/bootstrap/config/config.yml
    /var/vcap/packages/bootstrap/bin/cf-mysql-bootstrap -configPath=/var/vcap/jobs/bootstrap/config/config.yml
    echo 'Bootstrap errand completed'
    exit 0
    Errand `bootstrap' completed successfully (exit code 0)
    </pre>   
    
1. If the errand fails, run the bootstrap errand command again after a few minutes. The bootstrap errand may not work immediately.

1. See that the errand completes successfully in the shell output and continue to [Restore the BOSH Configuration](#reset-deployment) below.
    <p class="note"><strong>Note:</strong> After you complete the bootstrap errand, you may still see instances in the <code>failing</code> state. Continue to the next section anyway.</p>

##### <a id="reset-deployment"></a> Restore the BOSH Configuration 

<p class="note warning"><strong>WARNING:</strong> If you do not set each of your ignored instances to <code>unignore</code>, your instances are never updated in future deploys.</p>

To restore your BOSH configuration to its previous state, this procedure unignores each instance that was previously ignored.

1. Set each ignored instance to `unignore`.

    ```
    bosh -e MY-ENV -d MY-DEP unignore mysql/INSTANCE_GUID
    ```

1. Redeploy.

    ```
    bosh -e MY-ENV -d MY-DEP deploy
    ```

1. Validate that all `mysql` instances are in a `running` state.

    ```
    bosh -e YOUR-ENV -d YOUR-DEPLOYMENT instances
    ```


## <a id="manual-bootstrap"></a> Bootstrap Manually 

If the bootstrap errand is not able to automatically recover the cluster, you might need to do the steps manually. 

<p class="note warning"><strong>WARNING:</strong> The following procedures are prone to user error and can result in lost data if followed incorrectly. Follow the procedure in <a href="#assisted-bootstrap">Bootstrap with the BOSH Errand</a> above first, and only resort to the manual process if the errand fails to repair the cluster.</p>

Do the procedures in the sections below to manually bootstrap your cluster. Fresh installs of PCF v2.3 use a [Percona server](https://www.percona.com/software/mysql-database/percona-server) for their internal system MySQL databases (called MySQL or `mysqld` below), while installations of PCF v2.3 that were upgraded from PCF v2.1 use [MariaDB](https://mariadb.org/) if you did not migrate your databases to Percona during the upgrade process. Use the commands below that are appropriate for your installation of PCF.

### <a id="shut-down-mariadb"></a> Shut Down MariaDB or MySQL

Do the following for each node in the cluster:

1. SSH into the node. See the [BOSH CLI v2 instructions](https://docs.pivotal.io/pivotalcf/1-11/customizing/trouble-advanced.html#ssh-v2) for SSHing into BOSH-deployed VMs.

1. Shut down the `mariadb` or `mysqld` process on the node, depending on which database is running. Run either `monit stop mariadb_ctrl` (for `mariadb`) or `monit stop galera-init` (for `mysqld`).

Re-bootstrapping the cluster is not successful unless you shut down the `mariadb` or `mysqld` process on all nodes in the cluster.

### <a id="choose-node"></a> Choose Node to Bootstrap 

To choose the node to bootstrap, you must find the node with the highest transaction sequence number (`seqno`).

Do the following to find the node with the highest `seqno`:

1. Run the following command from the node:    
    ```
    cat /var/vcap/store/mysql/grastate.dat | grep 'seqno:'
    ```

1. If a node shut down gracefully, the `seqno` is in the Galera state file. Retrieve the `seqno` and continue to [Bootstrap the First Node](#set-bootstrap-node). 
<br><br>
If a node crashed or was killed, the `seqno` in the Galera state file is recorded as `-1`. In this case, the `seqno` might be recoverable from the database. Run the following command to start up the database, log the recovered `seqno`, and then exit:
    ```
    /var/vcap/packages/mariadb/bin/mysqld --wsrep-recover
    ```
    Scan the error log for the recovered `seqno`. It is the last number after the group id (`uuid`). For example:
    <pre class="terminal">
    $ grep "Recovered position" /var/vcap/sys/log/mysql/mysql.err.log | tail -1
    150225 18:09:42 mysqld_safe WSREP: Recovered position e93955c7-b797-11e4-9faa-9a6f0b73eb46:15
    </pre>
    If the node never connected to the cluster before crashing, it may not even have a group ID (`uuid` in `grastate.dat`). In this case, there is nothing to recover. Unless all nodes crashed this way, do not choose this node for bootstrapping.

1. After determining the `seqno` for all nodes in your cluster, identify the node with the highest `seqno`. If all nodes have the same `seqno`, you can choose any node as the new bootstrap node.

### <a id="set-bootstrap-node"></a> Bootstrap the First Node

After determining the node with the highest `seqno`, do the following to bootstrap the node:

<p class="note"><strong>Note:</strong> Only run these bootstrap commands on the node with the highest <code>seqno</code>. Otherwise the node with the highest <code>seqno</code> is unable to join the new cluster unless its data is abandoned. Its <code>mariadb</code> or <code>mysqld</code> process exits with an error.</p>

1. On the new bootstrap node, update the state file and restart the `mariadb` or `mysqld` process. Run either of the following commands, depending on which database is running:
    <pre><code>echo -n "NEEDS_BOOTSTRAP" > /var/vcap/store/mysql/state.txt
    monit start mariadb_ctrl</code></pre>
    <pre><code>echo -n "NEEDS_BOOTSTRAP" > /var/vcap/store/mysql/state.txt
    monit start galera-init</code></pre>

1. It can take up to ten minutes for `monit` to start the `mariadb` or `mysqld` process.
   To check if the `mariadb` or `mysqld` process has started successfully, run the following command:
    <pre><code>watch monit summary</code></pre>

### <a id="restart-nodes"></a> Restart Remaining Nodes

1. After the bootstrapped node is running, start the `mariadb` or `mysqld` process on the remaining nodes with `monit`. From the bootstrap node, run either `monit start mariadb_ctrl` (for `mariadb`) or `monit start galera-init` (for `mysqld`).
    If the node is prevented from starting by the [Interruptor](https://docs.pivotal.io/p-mysql/interruptor.html), do the manual procedure to force the node to rejoin the cluster, documented in [Pivotal Knowledge Base](https://discuss.pivotal.io/hc/en-us/articles/115014258668). 
    <p class="note warning"><strong>WARNING:</strong> Forcing a node to rejoin the cluster is a destructive procedure.
       Only do the procedure with the assistance of <a href="https://support.pivotal.io">Pivotal Support</a>.</p>

1. If the `monit start` command fails, it might be because the node with the highest `seqno` is the lowest BOSH-indexed node (`mysql/0`). In this case, do the following:
    1. From the Ops Manager VM, use the BOSH CLI to make BOSH ignore updating `mysql/0`:
        ```
        bosh -e MY-ENV -d MY-DEP ignore mysql/0
        ```
    1. Go to Ops Manager in a browser and log in.
    1. Click **Review Pending Changes**, then **Apply Changes**.
    1. When the deploy finishes, run the following command from the Ops Manager VM:
        ```
        bosh -e MY-ENV -d MY-DEP unignore mysql/0
        ```

1. Verify that the new nodes have successfully joined the cluster. SSH into the bootstrap node and run the following command to output the total number of nodes in the cluster:
    <pre><code>mysql> SHOW STATUS LIKE 'wsrep_cluster_size';</code></pre>